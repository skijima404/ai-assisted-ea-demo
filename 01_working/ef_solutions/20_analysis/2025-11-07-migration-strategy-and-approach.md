---
date: 2025-11-07
tags: [analysis, migration, transition-architecture]
confidence: ★★★☆☆
---

# 移行戦略とアプローチ

> **GenAI向けの注意事項**: このファイルは `01_working/20_analysis/` フォルダに格納されており、確実度 ★★★☆☆（一次メモを整理した分析結果。ある程度検証されているが、確定的ではない）です。示唆は確定事項ではなく、分析段階の推論である可能性があります。最終的な意思決定には、`03_artifacts/` フォルダの成果物を参照してください。

## 観察事実 (Observation)

### 現状のシステム間連携
- 社内システムではWeb APIが実装されておらず、一般的なStrangler Fig Patternが使用できない
- システム間のデータのやり取りはファイル（CSV）とバッチで実施されている
- CSV連携の利用箇所:
  - コンビニシステム → 人事システム
  - コンビニシステム → 社食システム
  - 社食システム → 人事システム
  - 人事システム → 社食システム

### Big Bangアプローチのリスク
- Big Bang移行（一括移行）はリスクが高く、何らかの方法で少しずつ切り出す必要がある
- しかし、APIが存在しないため、トラフィックのルーティングやパケットミラーリングといった一般的な手法が使えない

### データ流通点をインターフェースとみなすアプローチ
- CSV、テーブル、トピックといったデータの流通点をインターフェースとみなせば、Strangler Fig Patternの思想を適用できる可能性
- Strangler Fig Patternの重要な点は、トラフィックのルーティングを簡単に切り替えたり、パケットミラーリングができる点
- これを別の方法（データ流通点の置き換え）で実現できないか

### CSV to Kafkaへの移行
- 移行の最初のステップとしてCSV → Kafkaが適している：
  - 他の移行ステップより難易度が低い
  - 開発チーム内のQuick Winを演出できる
  - 後続のステップでKafkaを多用するため、この段階で知見を集めることで後続の難易度を下げられる
- コンビニシステムとの連携には猶予を持たせる方法：
  - コンビニシステム → CSV → CSV to Kafka変換サービス（Camel等）→ Kafka
  - CSV to Kafka変換サービスはこちらで作成する

### 並行稼働とパケットミラーリング
- リグレッションテストの代替案として、新旧の並行稼働を使ったテストが考えられる
- 参考: STAR by Mike Amundsen
- 旧環境の処理結果が割引部分を除いて正しいのであれば:
  - 新旧の並行稼働を実施
  - パケットミラーリングやそれに類する方法で同じデータを新旧に流す
  - 処理結果をDBから抜いてきて比較・突き合わせ
- OpenShiftや監視ツール、API Gateway、Service Meshのメトリクスを使い、デプロイメント直後は密な監視を実施
  - 基本ダークローンチ、ユーザー公開とはタイミングをずらす
  - Canary Releaseも活用する

## 示唆 (Implication)

### 移行戦略の基本方針
1. **データ流通点を移行の境界とする**: APIが存在しない環境では、CSV、テーブル、トピックといったデータの流通点をインターフェースとみなし、そこを境界として段階的に置き換える
2. **CSV to Kafkaを第一ステップとする**: 学習コストと技術的難易度のバランスが良く、後続ステップの基盤となる
3. **並行稼働による検証**: リグレッションテストが不十分な場合、並行稼働とパケットミラーリングで実データを使った検証を行う

### 移行リスクの軽減策
- **ダークローンチとCanary Release**: ユーザー公開とデプロイメントのタイミングをずらし、段階的に検証
- **密な監視体制**: OpenShift、監視ツール、Service Meshのメトリクスを活用
- **外部システムへの配慮**: コンビニシステムなど、開発チームとの連携が少ないシステムには、CSV to Kafka変換サービスを提供し、移行タイミングに猶予を持たせる

### 技術的な課題
- **パケットミラーリングの実現方法**: API経由ではない環境で、どのようにパケットミラーリングを実現するか
- **データ整合性の検証**: 新旧システムの処理結果を比較する仕組みの構築
- **トラフィック切り替えの実現**: データ流通点をインターフェースとした場合の、トラフィック切り替え方法

## 改善の方向性 (Improvement Directions)

### 1. CSV to Kafkaへの移行を第一ステップとする
- **目的**: 開発チームのKafka習熟、Quick Winの演出、後続ステップの基盤整備
- **実装方針**:
  - CSV to Kafka変換サービス（Camel等）を構築
  - コンビニシステムなど外部システムには、CSV to Kafka変換サービスを提供
  - 社食システムと人事システムは、直接Kafkaに接続
- **関連原則**: ADR-0003 (Event Driven Architecture)

### 2. 並行稼働とパケットミラーリングによる検証
- **目的**: リグレッションテストが不十分な場合の代替検証手法
- **実装方針**:
  - 新旧システムに同じデータを流し、処理結果を比較
  - OpenShift、監視ツール、Service Meshのメトリクスを活用した密な監視
  - ダークローンチとCanary Releaseによる段階的な検証
- **関連原則**: ADR-0007 (Observability)

### 3. データ流通点をインターフェースとしたStrangler Fig Pattern
- **目的**: APIが存在しない環境での段階的な移行
- **実装方針**:
  - CSV、テーブル、トピックといったデータの流通点を境界として、段階的に置き換え
  - トラフィック切り替えは、データソースの切り替えで実現
- **関連原則**: ADR-0004 (Microservices Architecture)

### 4. 移行順序の最適化
- **目的**: 依存関係を考慮した移行順序の設計
- **実装方針**:
  - 移行の各断面で並行稼働アプローチが成立するかを確認しながら、Transition Architectureを設計
  - 成立しなさそうな場合は、他の方法を検討
- **関連成果物**: Transition Architecture (Phase F)


