# Backcasting Review - Improvement Proposals

**Date**: 2025-11-13  
**Priority**: Critical & High items  
**Status**: Draft for Review

---

## Overview

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€Backcasting Mapã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯ã§æ¤œå‡ºã•ã‚ŒãŸå•é¡Œç‚¹ã«å¯¾ã™ã‚‹å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®å„ªå…ˆåº¦ã§å¯¾å¿œã‚’æ¨å¥¨ã—ã¾ã™ï¼š

- ğŸ”´ **Critical**: å³åº§ã«å¯¾å¿œã™ã¹ãï¼ˆPhase Gé–‹å§‹å‰ã«å¿…é ˆï¼‰
- ğŸŸ¡ **High**: Phase Gé–‹å§‹å‰ã«å¯¾å¿œã™ã¹ã
- ğŸŸ¢ **Medium**: Phase Gä¸­ã«å¯¾å¿œå¯èƒ½

---

## ğŸ”´ Critical Priority

### Proposal 1: DRæˆ¦ç•¥ã®ç­–å®š

**å¯¾è±¡**: Target Architecture (`03_arch-artifacts/target/container-diagram.md`)  
**Root Cause**: rc-019 (Insufficient DR testing), rc-030, rc-018  
**Symptom**: rf-006 (DR switchover failure)  
**Threatened Success Criteria**: sc-006 (Day 2 Operation Success)

#### è¿½åŠ ã™ã¹ãã‚»ã‚¯ã‚·ãƒ§ãƒ³

Target Architectureã«ä»¥ä¸‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼š

```markdown
## Disaster Recovery Strategy

### Overview
æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯çµ¦ä¸å¤©å¼•ãæ±ºæ¸ˆã‚’æ‰±ã†ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ãƒˆã‚„é•·æ™‚é–“ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã¯æ¥­å‹™ã«é‡å¤§ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚ä»¥ä¸‹ã®DRæˆ¦ç•¥ã«ã‚ˆã‚Šã€äº‹æ¥­ç¶™ç¶šæ€§ã‚’ç¢ºä¿ã™ã‚‹ã€‚

### RTO/RPO
- **RTO (Recovery Time Objective)**: 4 hours
  - æ ¹æ‹ : çµ¦ä¸å¤©å¼•ãã¯æœˆæ¬¡ç· ã‚ã®ãŸã‚ã€4æ™‚é–“ä»¥å†…ã®å¾©æ—§ã§ã‚ã‚Œã°æ¥­å‹™å½±éŸ¿ã¯æœ€å°é™
- **RPO (Recovery Point Objective)**: 1 hour
  - æ ¹æ‹ : æ˜¼ãƒ”ãƒ¼ã‚¯æ™‚ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ãƒˆã‚’1æ™‚é–“ä»¥å†…ã«æŠ‘ãˆã‚‹

### Backup Strategy

#### PostgreSQL
- **æ–¹å¼**: Continuous WAL (Write-Ahead Logging) archiving
- **ä¿å­˜å…ˆ**: Object Storage (S3-compatible)
- **ä¿æŒæœŸé–“**: 
  - Daily backup: 30 days
  - Weekly backup: 3 months
  - Monthly backup: 1 year
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒŸãƒ³ã‚°**: æ¯æ—¥æ·±å¤œ2:00ï¼ˆãƒãƒƒãƒå‡¦ç†å¾Œï¼‰
- **æš—å·åŒ–**: AES-256 (at rest and in transit)

#### Kafka
- **æ–¹å¼**: Multi-region replication (MirrorMaker 2)
- **ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**: 3 replicas (ç•°ãªã‚‹Availability Zone)
- **ä¿æŒæœŸé–“**: 30 days
- **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§**: Topic-level checksum validation

#### Application Configuration
- **æ–¹å¼**: GitOps (ArgoCD)
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: Git repository (è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—)

### Failover Strategy

#### Architecture
- **æ§‹æˆ**: Active-Standby
- **Primary Site**: Data Center A (Tokyo)
- **DR Site**: Data Center B (Osaka)
- **Replication**: 
  - PostgreSQL: Streaming replication (async)
  - Kafka: MirrorMaker 2 (async)
  - Object Storage: Cross-region replication

#### Failover Procedure
1. **Detection**: Monitoring system detects primary site failure
2. **Decision**: On-call engineer confirms failover necessity (within 15 min)
3. **Switchover**: 
   - Stop traffic to primary site (API Gateway config update)
   - Promote standby database to primary
   - Update DNS records (TTL: 60s)
   - Resume traffic to DR site
4. **Validation**: Smoke test on DR site
5. **Monitoring**: Enhanced monitoring for 24 hours

#### Failback Procedure
1. Restore primary site
2. Sync data from DR to primary (reverse replication)
3. Validate data consistency
4. Planned switchback during maintenance window

### DR Testing

#### Quarterly DR Switchover Test
- **Frequency**: Every quarter (Jan, Apr, Jul, Oct)
- **Scope**: 
  - Full failover to DR site
  - Run in production environment (off-peak hours)
  - Validate RTO/RPO compliance
- **Duration**: 4 hours (including failback)
- **Participants**: SRE, DBA, Application team, Business stakeholder

#### Annual Full Disaster Recovery Drill
- **Frequency**: Once per year
- **Scope**: 
  - Simulate complete data center failure
  - Test all recovery procedures
  - Validate backup restoration
  - Update runbooks based on lessons learned
- **Duration**: 1 day
- **Participants**: All teams + external stakeholders

### Monitoring & Alerting

#### Replication Lag Monitoring
- **Metric**: PostgreSQL replication lag
- **Threshold**: 
  - Warning: > 5 minutes
  - Critical: > 15 minutes
- **Action**: Alert on-call engineer

#### Backup Validation
- **Frequency**: Daily
- **Method**: Automated restore test to test environment
- **Validation**: 
  - Backup file integrity check
  - Sample data restoration
  - Application smoke test

### Runbooks
- DR Failover Runbook: `docs/runbooks/dr-failover.md`
- Backup Restoration Runbook: `docs/runbooks/backup-restore.md`
- DR Test Runbook: `docs/runbooks/dr-test.md`
```

#### Transition Architecture Step 5ã¸ã®è¿½åŠ 

`03_arch-artifacts/transition/step-5-overview-decoupling-canteen-resources.md` ã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```markdown
## DR Testing (Exit Criteria ã«è¿½åŠ )

### DR Readiness Validation
- DR Failover Runbook å®Œæˆ
- Quarterly DR Switchover Test å®Ÿæ–½ï¼ˆ1å›ä»¥ä¸Šï¼‰
- RTO/RPO é”æˆç¢ºèª
- DR Site ã§ã® Smoke Test åˆæ ¼
```

---

### Proposal 2: å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æºã®æ˜ç¤º

**å¯¾è±¡**: Target Architecture (`03_arch-artifacts/target/container-diagram.md`)  
**Root Cause**: rc-012 (External system dependencies not captured)  
**Symptom**: rf-003 (Capacity shortage)  
**Threatened Success Criteria**: sc-005 (Day 1 Operation Success)

#### å•é¡Œç‚¹
ç¾åœ¨ã®Target Architectureã«ã¯ã€äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã¨ç¤¾å†…ã‚³ãƒ³ãƒ“ãƒ‹ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æºãŒå›³ç¤ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚

#### æ”¹å–„ææ¡ˆ

Container Diagramã«ä»¥ä¸‹ã®å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã‚’è¿½åŠ ï¼š

```markdown
%% å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ 
subgraph External["External Systems"]
  HRSystem[äººäº‹ã‚·ã‚¹ãƒ†ãƒ \n(HR App)]:::external
  ConvenienceStore[ç¤¾å†…ã‚³ãƒ³ãƒ“ãƒ‹ã‚·ã‚¹ãƒ†ãƒ \n(POS)]:::external
end

%% å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æº
HRSystem -->|Produce: ç¤¾å“¡ãƒã‚¹ã‚¿å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆ| Kafka
Kafka -->|Consume: æ±ºæ¸ˆã‚¤ãƒ™ãƒ³ãƒˆ| HRSystem

ConvenienceStore -->|Produce: ã‚³ãƒ³ãƒ“ãƒ‹æ±ºæ¸ˆã‚¤ãƒ™ãƒ³ãƒˆ| Kafka

%% ã‚¹ã‚¿ã‚¤ãƒ«
classDef external fill:#ffe6e6,stroke:#d32f2f,rx:6,ry:6;
```

#### ãƒ‡ãƒ¼ã‚¿é€£æºä»•æ§˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ 

```markdown
## External System Integration

### äººäº‹ã‚·ã‚¹ãƒ†ãƒ  (HR System)

#### Inbound: ç¤¾å“¡ãƒã‚¹ã‚¿å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆ
- **Source**: äººäº‹ã‚·ã‚¹ãƒ†ãƒ 
- **Target**: Employee API (via Kafka)
- **Topic**: `hr.employee.events`
- **Format**: Avro
- **Schema**:
  ```json
  {
    "employee_id": "string",
    "name": "string",
    "department": "string",
    "employment_status": "enum[ACTIVE, INACTIVE, ON_LEAVE]",
    "updated_at": "timestamp"
  }
  ```
- **Frequency**: Real-time (CDC via Debezium)
- **Volume**: ~10 events/day (average), 100 events/day (peak during HR operations)

#### Outbound: æ±ºæ¸ˆã‚¤ãƒ™ãƒ³ãƒˆ
- **Source**: Bill API, Transaction API
- **Target**: äººäº‹ã‚·ã‚¹ãƒ†ãƒ 
- **Topic**: `canteen.billing.events`
- **Format**: Avro
- **Schema**:
  ```json
  {
    "billing_id": "string",
    "employee_id": "string",
    "period": "string (YYYY-MM)",
    "total_amount": "int",
    "transaction_count": "int",
    "created_at": "timestamp"
  }
  ```
- **Frequency**: Daily (batch at 2:00 AM)
- **Volume**: ~1000 events/day

### ç¤¾å†…ã‚³ãƒ³ãƒ“ãƒ‹ã‚·ã‚¹ãƒ†ãƒ  (Convenience Store)

#### Inbound: ã‚³ãƒ³ãƒ“ãƒ‹æ±ºæ¸ˆã‚¤ãƒ™ãƒ³ãƒˆ
- **Source**: ç¤¾å†…ã‚³ãƒ³ãƒ“ãƒ‹ã‚·ã‚¹ãƒ†ãƒ 
- **Target**: Transaction API (via Kafka)
- **Topic**: `convenience-store.payment.events`
- **Format**: Avro
- **Schema**:
  ```json
  {
    "transaction_id": "string",
    "employee_id": "string",
    "amount": "int",
    "items": "array<item>",
    "timestamp": "timestamp"
  }
  ```
- **Frequency**: Real-time
- **Volume**: ~500 transactions/day

### Error Handling
- **Retry Policy**: Exponential backoff (max 3 retries)
- **Dead Letter Queue**: `*.dlq` topic for failed messages
- **Monitoring**: Alert on DLQ message count > 10
```

---

### Proposal 3: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼æ–¹æ³•ã®ç¢ºå®š

**å¯¾è±¡**: 
- `03_arch-artifacts/transition/step-1-overview-csv-to-kafka.md`
- `03_arch-artifacts/transition/step-2-overview-separating-payments.md`

**Root Cause**: rc-027 (Data verification method not defined)  
**Symptom**: rf-002 (Production data contamination)  
**Threatened Success Criteria**: sc-004 (Successful Migration)

#### å•é¡Œç‚¹
Step 1, 2ã§ã€Œçªåˆãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¨™æº–åŒ–ã€ã€Œçªåˆé »åº¦ã‚’æ˜ç¤ºã—ã€è‡ªå‹•åŒ–ã‚’**æ¤œè¨**ã€ã¨ã‚ã‚‹ãŒã€å…·ä½“çš„ãªæ¤œè¨¼æ–¹æ³•ãŒç¢ºå®šã—ã¦ã„ã¾ã›ã‚“ã€‚

#### æ”¹å–„ææ¡ˆ: Step 1ã¸ã®è¿½åŠ 

`step-1-overview-csv-to-kafka.md` ã® Mitigations ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```markdown
## Data Verification Strategy (è©³ç´°)

### æ¤œè¨¼ã‚¹ã‚³ãƒ¼ãƒ—

#### Phase 1: ä¸¦è¡Œç¨¼åƒæœŸé–“ï¼ˆæœ€å¤§3ãƒ¶æœˆï¼‰
- æ—§çµŒè·¯ï¼ˆCSVï¼‰ã¨æ–°çµŒè·¯ï¼ˆKafkaï¼‰ã‚’ä¸¦è¡Œç¨¼åƒ
- æ—¥æ¬¡ã§å…¨ä»¶çªåˆã‚’å®Ÿæ–½

#### Phase 2: æ–°çµŒè·¯ã®ã¿ï¼ˆ1ãƒ¶æœˆï¼‰
- æ–°çµŒè·¯ï¼ˆKafkaï¼‰ã®ã¿ã§ç¨¼åƒ
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¤œè¨¼ã¨ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–

### æ¤œè¨¼å¯¾è±¡ãƒ‡ãƒ¼ã‚¿

| ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥ | æ¤œè¨¼ãƒ¬ãƒ™ãƒ« | æ¤œè¨¼é »åº¦ | è¨±å®¹å·®ç•° |
|-----------|----------|---------|---------|
| æ±ºæ¸ˆå±¥æ­´ | å…¨ä»¶çªåˆ | æ—¥æ¬¡ | 0ä»¶ |
| ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥æ—¥æ¬¡åˆè¨ˆ | é›†è¨ˆå€¤çªåˆ | æ—¥æ¬¡ | 0å†† |
| ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥æœˆæ¬¡åˆè¨ˆ | é›†è¨ˆå€¤çªåˆ | æœˆæ¬¡ | 0å†† |
| ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ•° | ã‚«ã‚¦ãƒ³ãƒˆçªåˆ | æ—¥æ¬¡ | 0ä»¶ |

### æ¤œè¨¼æ–¹æ³•

#### 1. å…¨ä»¶çªåˆ (Record-level Verification)

**å¯¾è±¡**: æ±ºæ¸ˆå±¥æ­´  
**æ–¹æ³•**: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³IDã‚’ã‚­ãƒ¼ã«æ–°æ—§ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’çªåˆ

```python
# çªåˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (conceptual)
def verify_transaction_records(date):
    old_records = fetch_from_csv(date)
    new_records = fetch_from_kafka_topic(date)
    
    # IDã§ã‚½ãƒ¼ãƒˆ
    old_sorted = sort_by_id(old_records)
    new_sorted = sort_by_id(new_records)
    
    # å·®åˆ†æ¤œå‡º
    missing_in_new = old_sorted - new_sorted
    extra_in_new = new_sorted - old_sorted
    mismatched = []
    
    for old, new in zip(old_sorted, new_sorted):
        if old.id == new.id:
            if not records_match(old, new, tolerance=0):
                mismatched.append((old, new))
    
    return {
        "missing": missing_in_new,
        "extra": extra_in_new,
        "mismatched": mismatched
    }

def records_match(old, new, tolerance=0):
    # é‡‘é¡ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’æ¯”è¼ƒ
    return (
        old.amount == new.amount and
        abs(old.timestamp - new.timestamp) <= tolerance and
        old.employee_id == new.employee_id
    )
```

**å‡ºåŠ›**: 
- å·®åˆ†ãƒ¬ãƒãƒ¼ãƒˆ (CSV)
- ä¸æ•´åˆãŒã‚ã‚‹å ´åˆã¯ã‚¢ãƒ©ãƒ¼ãƒˆç™ºå ±

#### 2. é›†è¨ˆå€¤çªåˆ (Aggregation Verification)

**å¯¾è±¡**: ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥æ—¥æ¬¡åˆè¨ˆã€æœˆæ¬¡åˆè¨ˆ  
**æ–¹æ³•**: SQLã‚¯ã‚¨ãƒªã§é›†è¨ˆã—ã€æ–°æ—§ã‚·ã‚¹ãƒ†ãƒ ã®çµæœã‚’æ¯”è¼ƒ

```sql
-- æ—§ã‚·ã‚¹ãƒ†ãƒ ï¼ˆCSVå–è¾¼å¾Œã®DBï¼‰
SELECT 
    employee_id,
    DATE(transaction_time) as date,
    SUM(amount) as total_amount,
    COUNT(*) as transaction_count
FROM old_transactions
WHERE DATE(transaction_time) = '2025-11-13'
GROUP BY employee_id, DATE(transaction_time);

-- æ–°ã‚·ã‚¹ãƒ†ãƒ ï¼ˆKafkaçµŒç”±ã®DBï¼‰
SELECT 
    employee_id,
    DATE(transaction_time) as date,
    SUM(amount) as total_amount,
    COUNT(*) as transaction_count
FROM new_transactions
WHERE DATE(transaction_time) = '2025-11-13'
GROUP BY employee_id, DATE(transaction_time);

-- å·®åˆ†æ¤œå‡º
SELECT 
    COALESCE(o.employee_id, n.employee_id) as employee_id,
    o.total_amount as old_total,
    n.total_amount as new_total,
    (n.total_amount - o.total_amount) as diff
FROM old_aggregated o
FULL OUTER JOIN new_aggregated n
    ON o.employee_id = n.employee_id AND o.date = n.date
WHERE o.total_amount != n.total_amount
   OR o.total_amount IS NULL
   OR n.total_amount IS NULL;
```

#### 3. ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¤œè¨¼ (Sample Verification)

**å¯¾è±¡**: Phase 2ï¼ˆæ–°çµŒè·¯ã®ã¿ï¼‰ã§ã®ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯æ¤œè¨¼  
**æ–¹æ³•**: ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ1%ï¼‰ã§è©³ç´°æ¤œè¨¼

```python
def sample_verification(date, sample_rate=0.01):
    all_transactions = fetch_transactions(date)
    sample = random.sample(all_transactions, int(len(all_transactions) * sample_rate))
    
    for tx in sample:
        # ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«æ¤œè¨¼
        assert tx.amount > 0, "Amount must be positive"
        assert tx.employee_id is not None, "Employee ID required"
        assert tx.timestamp <= now(), "Future timestamp not allowed"
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
        employee = fetch_employee(tx.employee_id)
        assert employee.status == "ACTIVE", "Employee must be active"
```

### æ¤œè¨¼ãƒ„ãƒ¼ãƒ«

#### ä¸»ãƒ„ãƒ¼ãƒ«: Apache Camel + DataSet Component
- **ç†ç”±**: Step 3ã§Camelã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€åŒã˜ãƒ„ãƒ¼ãƒ«ã§çµ±ä¸€
- **æ©Ÿèƒ½**: 
  - CSV vs Kafka Topic ã®çªåˆ
  - é›†è¨ˆå€¤ã®æ¯”è¼ƒ
  - ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

#### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: Python ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- **ç†ç”±**: Camelã§å¯¾å¿œå›°é›£ãªè¤‡é›‘ãªçªåˆãƒ­ã‚¸ãƒƒã‚¯
- **æ©Ÿèƒ½**: 
  - ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®è©³ç´°çªåˆ
  - çµ±è¨ˆåˆ†æ
  - å¯è¦–åŒ–

#### ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: Grafana
- **ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: 
  - æ—¥æ¬¡çªåˆçµæœï¼ˆOK/NGä»¶æ•°ï¼‰
  - å·®åˆ†ä»¶æ•°ã®æ¨ç§»
  - æ¤œè¨¼æ‰€è¦æ™‚é–“

### ä¸æ•´åˆç™ºç”Ÿæ™‚ã®å¯¾å¿œãƒ•ãƒ­ãƒ¼

```mermaid
flowchart TD
    A[çªåˆå®Ÿè¡Œ] --> B{å·®ç•°æ¤œå‡º?}
    B -->|No| C[ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜]
    B -->|Yes| D[ã‚¢ãƒ©ãƒ¼ãƒˆç™ºå ±]
    D --> E[ãƒˆãƒªã‚¢ãƒ¼ã‚¸ä¼šè­°æ‹›é›†<br/>24æ™‚é–“ä»¥å†…]
    E --> F{å½±éŸ¿åº¦åˆ¤å®š}
    F -->|Critical| G[å³åº§ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯]
    F -->|High| H[æ ¹æœ¬åŸå› åˆ†æ<br/>48æ™‚é–“ä»¥å†…]
    F -->|Low| I[ãƒãƒƒã‚¯ãƒ­ã‚°ã«ç™»éŒ²]
    G --> J[äº‹å¾Œåˆ†æ]
    H --> K{ä¿®æ­£å¯èƒ½?}
    K -->|Yes| L[ä¿®æ­£å®Ÿè£…]
    K -->|No| G
    L --> M[å†æ¤œè¨¼]
    M --> B
```

#### å½±éŸ¿åº¦åˆ¤å®šåŸºæº–

| å½±éŸ¿åº¦ | å®šç¾© | ä¾‹ | å¯¾å¿œæœŸé™ |
|-------|------|----|---------| 
| Critical | é‡‘é¡ã®ä¸æ•´åˆ | ãƒ¦ãƒ¼ã‚¶ãƒ¼è«‹æ±‚é¡ãŒç•°ãªã‚‹ | å³åº§ |
| High | ãƒ‡ãƒ¼ã‚¿æ¬ æ | ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãŒæ¬ è½ | 48æ™‚é–“ |
| Medium | ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¸ä¸€è‡´ | ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ã‚ºãƒ¬ï¼ˆ<1ç§’ï¼‰ | 1é€±é–“ |
| Low | è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ã®ä¸ä¸€è‡´ | å•†å“åã®è¡¨è¨˜ã‚†ã‚Œ | ãƒãƒƒã‚¯ãƒ­ã‚° |

### Exit Criteriaï¼ˆPhase 1â†’Phase 2ç§»è¡Œæ¡ä»¶ï¼‰

- âœ… é€£ç¶š30æ—¥é–“ã€å·®ç•°0ä»¶
- âœ… é›†è¨ˆå€¤çªåˆï¼šé€£ç¶š30æ—¥é–“ã€å·®ç•°0å††
- âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼šçªåˆå‡¦ç†æ™‚é–“ < 30åˆ†/æ—¥
- âœ… é‹ç”¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†
- âœ… ãƒ“ã‚¸ãƒã‚¹æ‰¿èªå–å¾—
```

#### æ”¹å–„ææ¡ˆ: Step 2ã¸ã®è¿½åŠ 

`step-2-overview-separating-payments.md` ã® Mitigations ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã€ã€Œæ¤œè¨ã€ã‚’å‰Šé™¤ã—ã€ä»¥ä¸‹ã«ç½®ãæ›ãˆï¼š

```markdown
### ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼æˆ¦ç•¥

Step 1ã§ç¢ºç«‹ã—ãŸãƒ‡ãƒ¼ã‚¿æ¤œè¨¼æ–¹æ³•ã‚’ç¶™ç¶šé©ç”¨ï¼š
- **å…¨ä»¶çªåˆ**: æ—¥æ¬¡ï¼ˆMirrorçµŒç”±ã®æ–°æ—§ã‚·ã‚¹ãƒ†ãƒ ï¼‰
- **é›†è¨ˆå€¤çªåˆ**: æ—¥æ¬¡ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥æ±ºæ¸ˆåˆè¨ˆï¼‰
- **ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¤œè¨¼**: Phase 2ã§1%

è©³ç´°ã¯ `step-1-overview-csv-to-kafka.md` ã®Data Verification Strategyã‚’å‚ç…§ã€‚

**Step 2å›ºæœ‰ã®æ¤œè¨¼é …ç›®**:
- MirrorçµŒç”±ã®ãƒ‡ãƒ¼ã‚¿åˆ†å²ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ã‚‹ã‹
  - PayApp (æ–°ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹) ã¸ã®é…ä¿¡: 100%
  - æ—§App-DB ã¸ã®é…ä¿¡: 100%
- äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã¸ã®Kafkaé…ä¿¡ãŒæ—§CSVé€£æºã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã‹
```

---

## ğŸŸ¡ High Priority

### Proposal 4: ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£è¨ˆç”»ã®ç­–å®š

**å¯¾è±¡**: 
- Baseline Architecture (`03_arch-artifacts/baseline/functional-map.md`)
- Target Architecture (`03_arch-artifacts/target/container-diagram.md`)

**Root Cause**: rc-017 (Insufficient capacity planning), rc-011 (Baseline capacity not analyzed)  
**Symptom**: rf-003 (Capacity shortage)  
**Threatened Success Criteria**: sc-005 (Day 1 Operation Success)

#### Baselineã¸ã®è¿½åŠ 

`03_arch-artifacts/baseline/functional-map.md` ã«ä»¥ä¸‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼š

```markdown
## ç¾è¡Œã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½ç‰¹æ€§ï¼ˆCapacity Baselineï¼‰

### ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³

#### æ—¥æ¬¡ãƒ‘ã‚¿ãƒ¼ãƒ³
- **æ˜¼ãƒ”ãƒ¼ã‚¯æ™‚é–“å¸¯**: 11:30-13:00
- **ãƒ”ãƒ¼ã‚¯æ™‚TPS**: 50 transactions/second
- **å¹³å‡TPSï¼ˆå–¶æ¥­æ™‚é–“ï¼‰**: 10 transactions/second
- **1æ—¥ã‚ãŸã‚Šãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ•°**: ~2,000ä»¶

#### æœˆæ¬¡ãƒ‘ã‚¿ãƒ¼ãƒ³
- **æœˆåˆ**: é€šå¸¸
- **æœˆæœ«ï¼ˆç· ã‚å‡¦ç†ï¼‰**: ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹è² è·å¢—
  - ãƒãƒƒãƒå‡¦ç†æ™‚é–“: 2-3æ™‚é–“ï¼ˆæ·±å¤œ2:00-5:00ï¼‰
  - å‡¦ç†å¯¾è±¡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: ~40,000ä»¶/æœˆ

### ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ï¼ˆç¾è¡Œã‚·ã‚¹ãƒ†ãƒ ï¼‰

#### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼
- **CPUä½¿ç”¨ç‡**: å¹³å‡30%ã€ãƒ”ãƒ¼ã‚¯æ™‚60%
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡**: å¹³å‡50% (4GBä¸­2GB)
- **ã‚¹ãƒ¬ãƒƒãƒ‰æ•°**: å¹³å‡20ã€ãƒ”ãƒ¼ã‚¯æ™‚50

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆPostgreSQLï¼‰
- **åŒæ™‚æ¥ç¶šæ•°**: å¹³å‡10ã€ãƒ”ãƒ¼ã‚¯æ™‚30
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: 50GBï¼ˆ3å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
- **ã‚¯ã‚¨ãƒªå¿œç­”æ™‚é–“**: 
  - SELECTï¼ˆå˜ç´”ï¼‰: p95 < 50ms
  - SELECTï¼ˆJOINå¤šæ•°ï¼‰: p95 < 500ms
  - INSERT/UPDATE: p95 < 100ms

#### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
- **å¸¯åŸŸå¹…**: å¹³å‡5Mbpsã€ãƒ”ãƒ¼ã‚¯æ™‚20Mbps
- **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: 
  - ç¤¾å†…ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: < 5ms
  - å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ï¼ˆäººäº‹ï¼‰: < 50ms

### å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æºã®æ€§èƒ½

#### äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã¨ã®CSVé€£æº
- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: 
  - æ—¥æ¬¡ï¼ˆç¤¾å“¡ãƒã‚¹ã‚¿ï¼‰: ~1MB
  - æœˆæ¬¡ï¼ˆæ±ºæ¸ˆãƒ‡ãƒ¼ã‚¿ï¼‰: ~5MB
- **è»¢é€æ™‚é–“**: < 1åˆ†
- **å‡¦ç†æ™‚é–“**: ~10åˆ†

#### ã‚³ãƒ³ãƒ“ãƒ‹ã‚·ã‚¹ãƒ†ãƒ ã¨ã®CSVé€£æº
- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: 
  - æ—¥æ¬¡ï¼ˆãƒ¬ã‚·ãƒ¼ãƒˆæ˜ç´°ï¼‰: ~2MB
  - æœˆæ¬¡ï¼ˆæ±ºæ¸ˆãƒ‡ãƒ¼ã‚¿ï¼‰: ~3MB
- **è»¢é€æ™‚é–“**: < 1åˆ†
- **å‡¦ç†æ™‚é–“**: ~5åˆ†

### ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°
- **ç¤¾å“¡ç·æ•°**: 1,000äºº
- **ç¤¾é£Ÿåˆ©ç”¨è€…**: ~500äºº/æ—¥
- **ã‚³ãƒ³ãƒ“ãƒ‹åˆ©ç”¨è€…**: ~300äºº/æ—¥
- **åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ãƒ¦ãƒ¼ã‚¶ãƒ¼**: ãƒ”ãƒ¼ã‚¯æ™‚200äºº
```

#### Target Architectureã¸ã®è¿½åŠ 

`03_arch-artifacts/target/container-diagram.md` ã«ä»¥ä¸‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼š

```markdown
## Capacity Planning

### Performance Requirementsï¼ˆéæ©Ÿèƒ½è¦ä»¶ï¼‰

#### APIå¿œç­”æ™‚é–“ï¼ˆSLOï¼‰
| API | p95ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | p99ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· |
|-----|-------------|-------------|
| Menu API | < 200ms | < 500ms |
| Payment API | < 300ms | < 800ms |
| Transaction API | < 200ms | < 500ms |
| Bill API | < 1s | < 2s |
| Employee API | < 200ms | < 500ms |
| History API | < 500ms | < 1s |

#### ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¦ä»¶
| ã‚µãƒ¼ãƒ“ã‚¹ | å¹³å‡TPS | ãƒ”ãƒ¼ã‚¯TPS | å‚™è€ƒ |
|---------|--------|---------|------|
| Payment API | 10 | 100 | æ˜¼ãƒ”ãƒ¼ã‚¯æ™‚ã®æ±ºæ¸ˆå‡¦ç† |
| Transaction API | 10 | 100 | åŒä¸Š |
| Menu API | 20 | 200 | æ˜¼ãƒ”ãƒ¼ã‚¯å‰ã®é–²è¦§é›†ä¸­ |
| Employee API | 1 | 10 | ä½é »åº¦ |

### Resource Allocation

#### Pod Resource Requests & Limits

```yaml
# ä¾‹: Payment API
resources:
  requests:
    memory: "512Mi"
    cpu: "250m"
  limits:
    memory: "1Gi"
    cpu: "500m"

# HPA (Horizontal Pod Autoscaler)
minReplicas: 2
maxReplicas: 10
targetCPUUtilizationPercentage: 70
targetMemoryUtilizationPercentage: 80
```

| Service | Replicas (min/max) | Memory (req/limit) | CPU (req/limit) |
|---------|-------------------|-------------------|-----------------|
| Payment API | 2/10 | 512Mi/1Gi | 250m/500m |
| Transaction API | 2/10 | 512Mi/1Gi | 250m/500m |
| Menu API | 2/10 | 256Mi/512Mi | 100m/250m |
| Bill API | 1/3 | 512Mi/1Gi | 250m/500m |
| Employee API | 1/3 | 256Mi/512Mi | 100m/250m |
| History API | 1/3 | 256Mi/512Mi | 100m/250m |
| Private API | 1/3 | 256Mi/512Mi | 100m/250m |
| UserProfile API | 1/3 | 256Mi/512Mi | 100m/250m |

#### Database Connection Pool

```yaml
# PostgreSQL Connection Pool (per service)
PaymentDB:
  min_connections: 5
  max_connections: 20
  connection_timeout: 30s

TransactionDB:
  min_connections: 5
  max_connections: 20
  connection_timeout: 30s

# ãã®ä»–ã®DB: min 2, max 10
```

#### Kafka Configuration

```yaml
# Topic Configuration
topics:
  canteen.payment.events:
    partitions: 6  # ä¸¦åˆ—å‡¦ç†ã®ãŸã‚
    replication_factor: 3  # å¯ç”¨æ€§ã®ãŸã‚
    retention: 30d
    
  hr.employee.events:
    partitions: 3
    replication_factor: 3
    retention: 30d

# Consumer Configuration
consumer:
  max_poll_records: 500
  session_timeout: 30s
  fetch_min_bytes: 1024
```

### Scaling Strategy

#### Auto-scaling Triggers

| Metric | Scale-out Threshold | Scale-in Threshold |
|--------|-------------------|-------------------|
| CPUä½¿ç”¨ç‡ | > 70% (5åˆ†é–“ç¶™ç¶š) | < 30% (10åˆ†é–“ç¶™ç¶š) |
| ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ | > 80% (5åˆ†é–“ç¶™ç¶š) | < 40% (10åˆ†é–“ç¶™ç¶š) |
| API Latency (p95) | > SLO Ã— 1.5 (2åˆ†é–“ç¶™ç¶š) | < SLO Ã— 0.5 (10åˆ†é–“ç¶™ç¶š) |
| Request Queue Length | > 100 | < 10 |

#### Scale-out Time
- **Target**: Podèµ·å‹•ã‹ã‚‰æº–å‚™å®Œäº†ã¾ã§ < 2åˆ†
- **Strategy**: 
  - ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®äº‹å‰ãƒ—ãƒ«
  - Readiness Probeã®æœ€é©åŒ–
  - Connection Pool ã® Warm-up

### Load Testing Plan

#### Test Scenarios
1. **é€šå¸¸è² è·ãƒ†ã‚¹ãƒˆ**: å¹³å‡TPS Ã— 1.5å€ã€30åˆ†é–“
2. **ãƒ”ãƒ¼ã‚¯è² è·ãƒ†ã‚¹ãƒˆ**: ãƒ”ãƒ¼ã‚¯TPS Ã— 1.2å€ã€15åˆ†é–“
3. **è€ä¹…ãƒ†ã‚¹ãƒˆ**: å¹³å‡TPSã€8æ™‚é–“
4. **ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ†ã‚¹ãƒˆ**: 0â†’ãƒ”ãƒ¼ã‚¯TPSã€ç¬é–“çš„
5. **ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ**: æœˆæ¬¡ç· ã‚å‡¦ç†ã€40,000ä»¶

#### Success Criteria
- âœ… ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒSLOä»¥å†…
- âœ… ã‚¨ãƒ©ãƒ¼ç‡ < 0.1%
- âœ… Auto-scalingãŒæ­£å¸¸å‹•ä½œ
- âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ãŒæ¯æ¸‡ã—ãªã„
- âœ… Kafka Consumer LagãŒç´¯ç©ã—ãªã„ (< 1000 messages)
```

---

### Proposal 5: é‹ç”¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ˜ç¤º

**å¯¾è±¡**: Target Architecture (`03_arch-artifacts/target/container-diagram.md`)  
**Root Cause**: rc-024 (Operational architecture was not considered)  
**Symptom**: rf-004 (Design-induced operational risk), rf-007 (Extended troubleshooting)  
**Threatened Success Criteria**: sc-006 (Day 2 Operation Success)

#### Target Architectureã¸ã®è¿½åŠ 

Container Diagramã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```markdown
%% Observability Platform
subgraph Observability["Observability Platform"]
  Prometheus[(Prometheus\nMetrics)]:::obs
  Grafana[Grafana\nDashboards]:::obs
  Loki[(Loki\nLogs)]:::obs
  Jaeger[(Jaeger\nTracing)]:::obs
  AlertManager[AlertManager]:::obs
end

%% Observabilityã¨ã®é€£æº
Bill -.->|metrics| Prometheus
Employee -.->|metrics| Prometheus
History -.->|metrics| Prometheus
Menu -.->|metrics| Prometheus
Payment -.->|metrics| Prometheus
Private -.->|metrics| Prometheus
Transaction -.->|metrics| Prometheus
UserProfile -.->|metrics| Prometheus

Bill -.->|logs| Loki
Employee -.->|logs| Loki
%% ... (ä»–ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚‚åŒæ§˜)

Bill -.->|traces| Jaeger
Payment -.->|traces| Jaeger
Transaction -.->|traces| Jaeger

Prometheus --> AlertManager
AlertManager -.->|notifications| ExternalAlertSystem[PagerDuty/Slack]:::external

classDef obs fill:#fff3e0,stroke:#ff9800,rx:6,ry:6;
```

æ–°è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³:

```markdown
## Observability Architecture

### Overview
ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–ã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ã®è¤‡é›‘æ€§ãŒå¢—ã™ãŸã‚ã€åŒ…æ‹¬çš„ãªObservabilityæˆ¦ç•¥ã‚’æ¡ç”¨ã™ã‚‹ã€‚Three Pillars of Observabilityï¼ˆMetricsã€Logsã€Tracesï¼‰ã‚’å®Ÿè£…ã€‚

### Metrics Collection

#### Platform: Prometheus + Grafana

#### Metrics Hierarchy

**Level 1: Infrastructure Metrics (OpenShiftæä¾›)**
- Node CPU/Memory usage
- Pod CPU/Memory usage
- Network I/O
- Disk I/O

**Level 2: Application Metrics (Spring Boot Actuator)**
- JVM metrics (heap, GC, threads)
- HTTP request metrics (rate, duration, errors)
- Database connection pool metrics
- Cache hit/miss ratio

**Level 3: Business Metrics (Custom)**
- Transaction count per service
- Payment success/failure rate
- Average transaction amount
- Daily active users

#### Key Metrics (SLIs)

| Service | Metric | Target (SLO) | Alert Threshold |
|---------|--------|-------------|----------------|
| Payment API | Availability | 99.5% | < 99% (5 min) |
| Payment API | Latency (p95) | < 300ms | > 450ms (2 min) |
| Payment API | Error Rate | < 0.5% | > 1% (2 min) |
| Transaction API | Availability | 99.5% | < 99% (5 min) |
| Transaction API | Latency (p95) | < 200ms | > 300ms (2 min) |
| Kafka | Consumer Lag | < 1000 msgs | > 5000 msgs (5 min) |
| PostgreSQL | Connection Pool | < 80% utilized | > 90% (2 min) |

### Log Aggregation

#### Platform: Loki + Grafana

#### Log Levels & Retention

| Level | Use Case | Retention | Storage |
|-------|----------|-----------|---------|
| ERROR | ã‚¨ãƒ©ãƒ¼ã€ä¾‹å¤– | 90 days | Hot |
| WARN | è­¦å‘Šã€ãƒªãƒˆãƒ©ã‚¤ | 30 days | Warm |
| INFO | ä¸»è¦ã‚¤ãƒ™ãƒ³ãƒˆ | 14 days | Warm |
| DEBUG | ãƒ‡ãƒãƒƒã‚°æƒ…å ± | 7 days | Cold |

#### Structured Logging Format (JSON)

```json
{
  "timestamp": "2025-11-13T12:34:56.789Z",
  "level": "INFO",
  "service": "payment-api",
  "trace_id": "a1b2c3d4e5f6",
  "span_id": "123456",
  "user_id": "emp001",
  "message": "Payment processed successfully",
  "context": {
    "transaction_id": "tx-12345",
    "amount": 850,
    "payment_method": "payroll_deduction"
  }
}
```

#### Log Query Examples

```logql
# éå»1æ™‚é–“ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ï¼ˆPayment APIï¼‰
{service="payment-api"} |= "ERROR" | json | timestamp > now() - 1h

# ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³è¿½è·¡
{service=~"payment-api|transaction-api"} | json | user_id="emp001"

# é«˜ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
{service="payment-api"} | json | duration > 1000
```

### Distributed Tracing

#### Platform: Jaeger

#### Trace Propagation
- **Protocol**: OpenTelemetry (OTLP)
- **Context Propagation**: W3C Trace Context headers
- **Sampling Rate**: 
  - Production: 10% (é€šå¸¸æ™‚), 100% (ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚)
  - Non-production: 100%

#### Trace Example Flow

```
User Request â†’ API Gateway â†’ Payment API â†’ Transaction API â†’ PostgreSQL
                                   â†“
                                 Kafka â†’ Bill API â†’ PostgreSQL
```

å„ã‚¹ãƒ‘ãƒ³:
- `api-gateway`: HTTP request handling
- `payment-api`: Payment validation
- `transaction-api`: Transaction creation
- `postgres`: Database query
- `kafka-producer`: Message publishing
- `kafka-consumer`: Message consumption
- `bill-api`: Bill generation

### Alerting Strategy

#### Alert Routing

```yaml
# AlertManager Configuration
route:
  receiver: 'team-canteen'
  group_by: ['alertname', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  
  routes:
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      continue: true
    
    - match:
        severity: warning
      receiver: 'slack-warnings'

receivers:
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: '<key>'
  
  - name: 'slack-warnings'
    slack_configs:
      - channel: '#canteen-alerts'
```

#### Alert Examples

**Critical Alerts** (PagerDuty)
- API Availability < 99% for 5 minutes
- Error Rate > 5% for 2 minutes
- Database Connection Pool > 95% for 2 minutes
- Kafka Consumer Lag > 10,000 messages for 5 minutes

**Warning Alerts** (Slack)
- API Latency (p95) > SLO Ã— 1.5 for 5 minutes
- Error Rate > 1% for 5 minutes
- Pod CPU > 80% for 10 minutes
- Disk Usage > 80%

### Dashboards

#### Level 1: Overview Dashboard (çµŒå–¶å±¤å‘ã‘)
- æ—¥æ¬¡ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ•°
- æ±ºæ¸ˆæˆåŠŸç‡
- ã‚·ã‚¹ãƒ†ãƒ å¯ç”¨æ€§
- ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆGreen/Yellow/Redï¼‰

#### Level 2: Service Dashboard (SREå‘ã‘)
- Per-service metrics (availability, latency, error rate)
- Resource utilization (CPU, memory)
- Dependency health (database, Kafka)
- Alert history

#### Level 3: Deep-dive Dashboard (é–‹ç™ºè€…å‘ã‘)
- Detailed trace analysis
- Database query performance
- Kafka consumer lag
- JVM metrics (heap, GC, threads)

### Runbook Integration
- å„ã‚¢ãƒ©ãƒ¼ãƒˆã«å¯¾å¿œã™ã‚‹Runbookã¸ã®ãƒªãƒ³ã‚¯ã‚’è¨˜è¼‰
- Runbook location: `docs/runbooks/`
- ä¾‹:
  - `runbooks/payment-api-high-latency.md`
  - `runbooks/kafka-consumer-lag.md`
  - `runbooks/database-connection-pool-exhausted.md`
```

---

## ğŸŸ¢ Medium Priority

### Proposal 6: ã‚µãƒ–ã‚·ã‚¹ãƒ†ãƒ é–“ã®Data Contractã®æ˜ç¤º

**å¯¾è±¡**: Transition Architecture (Step 1-5)  
**Root Cause**: rc-028 (Integration assumptions were inconsistent)  
**Symptom**: rf-003 (Capacity shortage), rf-012 (Numerous bugs occurred)

#### å„ã‚¹ãƒ†ãƒƒãƒ—ã«ã€ŒData Contractã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 

**Step 1**: `step-1-overview-csv-to-kafka.md`

```markdown
## Data Contract

### Kafka Topics

#### `canteen.transaction.events` (æ–°è¦ä½œæˆ)
**Purpose**: ç¤¾é£Ÿã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰æ±ºæ¸ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’é…ä¿¡

**Schema** (Avro):
```avro
{
  "type": "record",
  "name": "TransactionEvent",
  "namespace": "com.example.canteen",
  "fields": [
    {"name": "transaction_id", "type": "string", "doc": "ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å›ºæœ‰ID"},
    {"name": "employee_id", "type": "string", "doc": "ç¤¾å“¡ID"},
    {"name": "amount", "type": "int", "doc": "æ±ºæ¸ˆé‡‘é¡ï¼ˆå††ï¼‰"},
    {"name": "transaction_type", "type": "enum", "symbols": ["CANTEEN", "CONVENIENCE_STORE"]},
    {"name": "items", "type": {"type": "array", "items": "LineItem"}, "doc": "æ˜ç´°"},
    {"name": "timestamp", "type": "long", "logicalType": "timestamp-millis"}
  ]
}

{
  "type": "record",
  "name": "LineItem",
  "namespace": "com.example.canteen",
  "fields": [
    {"name": "item_id", "type": "string"},
    {"name": "item_name", "type": "string"},
    {"name": "quantity", "type": "int"},
    {"name": "unit_price", "type": "int"},
    {"name": "subtotal", "type": "int"}
  ]
}
```

**Configuration**:
- Partitions: 3
- Replication Factor: 3
- Retention: 30 days
- Compression: snappy

**Performance Requirements**:
- Throughput: å¹³å‡10 msg/s, ãƒ”ãƒ¼ã‚¯100 msg/s
- Latency (Producer): p95 < 50ms
- Latency (Consumer): p95 < 200ms

---

#### `hr.employee.events` (æ—¢å­˜ã€äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰é…ä¿¡)
**Purpose**: äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ç¤¾å“¡ãƒã‚¹ã‚¿å¤‰æ›´ã‚’é…ä¿¡

**Schema** (Avro):
```avro
{
  "type": "record",
  "name": "EmployeeEvent",
  "namespace": "com.example.hr",
  "fields": [
    {"name": "employee_id", "type": "string"},
    {"name": "name", "type": "string"},
    {"name": "department", "type": "string"},
    {"name": "employment_status", "type": "enum", "symbols": ["ACTIVE", "INACTIVE", "ON_LEAVE"]},
    {"name": "updated_at", "type": "long", "logicalType": "timestamp-millis"},
    {"name": "event_type", "type": "enum", "symbols": ["CREATE", "UPDATE", "DELETE"]}
  ]
}
```

**Configuration**:
- Partitions: 1 (ä½é »åº¦ã®ãŸã‚)
- Replication Factor: 3
- Retention: 90 days
- Compression: snappy

**Performance Requirements**:
- Throughput: å¹³å‡1 msg/day, ãƒ”ãƒ¼ã‚¯10 msg/day
- Latency (Consumer): p95 < 1s
```

**Step 2**: `step-2-overview-separating-payments.md`

```markdown
## Data Contract

### Mirror Configuration
**Input**: æ±ºæ¸ˆç«¯æœ«ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæœªå®šã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾å­˜ï¼‰
**Output**: 
1. PayApp (æ–°ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹) - KafkaçµŒç”±
2. æ—§App-DB - ç›´æ¥æ›¸è¾¼ã¿

### Kafka Topic (æ–°è¦ä½œæˆ)

#### `canteen.payment.raw.events`
**Purpose**: æ±ºæ¸ˆç«¯æœ«ã‹ã‚‰ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’MirrorãŒé…ä¿¡

**Schema** (Avro):
```avro
{
  "type": "record",
  "name": "PaymentRawEvent",
  "namespace": "com.example.canteen",
  "fields": [
    {"name": "terminal_id", "type": "string"},
    {"name": "employee_id", "type": "string"},
    {"name": "amount", "type": "int"},
    {"name": "timestamp", "type": "long", "logicalType": "timestamp-millis"},
    {"name": "raw_data", "type": "bytes", "doc": "ç«¯æœ«ã‹ã‚‰ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰"}
  ]
}
```

**Configuration**:
- Partitions: 6
- Replication Factor: 3
- Retention: 30 days

### REST API Contract (PayApp â†’ HR System)

#### Endpoint: `POST /api/v1/billing/events`
**Purpose**: äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã¸ã®æ±ºæ¸ˆã‚¤ãƒ™ãƒ³ãƒˆé…ä¿¡ï¼ˆKafkaçµŒç”±ã®éåŒæœŸå‡¦ç†ï¼‰

**Request Body** (JSON):
```json
{
  "billing_id": "bill-2025-11-13-001",
  "employee_id": "emp001",
  "period": "2025-11",
  "total_amount": 12500,
  "transaction_count": 15,
  "created_at": "2025-11-13T02:00:00Z"
}
```

**Response** (HTTP 202 Accepted):
```json
{
  "status": "accepted",
  "message_id": "kafka-msg-12345"
}
```

**Error Handling**:
- 4xx: Client error (validation failure) â†’ Retryä¸è¦ã€ã‚¢ãƒ©ãƒ¼ãƒˆç™ºå ±
- 5xx: Server error â†’ Exponential backoff retry (max 3å›)
```

---

### Proposal 7: ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã®æ˜ç¤º

**å¯¾è±¡**: Target Architecture (`03_arch-artifacts/target/container-diagram.md`)  
**Root Cause**: rc-020 (Insufficient testability strategy)  
**Symptom**: rf-012 (Numerous bugs occurred)

#### Target Architectureã¸ã®è¿½åŠ 

```markdown
## Testing Strategy

### Test Pyramid

```
         /\
        /E2E\          10% - End-to-End Tests
       /______\
      /        \
     / Integr. \       20% - Integration Tests
    /___________\
   /             \
  /  Unit Tests   \    70% - Unit Tests
 /_________________\
```

### Test Types

#### Unit Tests (70%)
**Scope**: å˜ä¸€ã‚¯ãƒ©ã‚¹/é–¢æ•°ã®ãƒ­ã‚¸ãƒƒã‚¯  
**Framework**: JUnit 5 + Mockito  
**Coverage Target**: 80% (line coverage)  
**Execution Time**: < 5 minutes (å…¨ãƒ†ã‚¹ãƒˆ)

**Example**:
```java
@Test
void shouldCalculateTotalAmount() {
    // Given
    List<LineItem> items = List.of(
        new LineItem("item1", 100, 2),
        new LineItem("item2", 150, 1)
    );
    
    // When
    int total = PaymentService.calculateTotal(items);
    
    // Then
    assertEquals(350, total);
}
```

#### Integration Tests (20%)
**Scope**: ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å†…ã®è¤‡æ•°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆ  
**Framework**: 
- Spring Boot Test (with `@SpringBootTest`)
- Testcontainers (PostgreSQL, Kafka)

**Coverage Target**: ä¸»è¦ãªãƒ“ã‚¸ãƒã‚¹ãƒ•ãƒ­ãƒ¼  
**Execution Time**: < 15 minutes

**Example**:
```java
@SpringBootTest
@Testcontainers
class PaymentAPIIntegrationTest {
    @Container
    static PostgreSQLContainer postgres = new PostgreSQLContainer("postgres:15");
    
    @Container
    static KafkaContainer kafka = new KafkaContainer("confluentinc/cp-kafka:7.5.0");
    
    @Test
    void shouldProcessPaymentAndPublishEvent() {
        // Given
        PaymentRequest request = new PaymentRequest("emp001", 850);
        
        // When
        PaymentResponse response = paymentAPI.processPayment(request);
        
        // Then
        assertEquals("SUCCESS", response.getStatus());
        
        // Verify Kafka message published
        ConsumerRecord<String, String> record = kafkaConsumer.poll(Duration.ofSeconds(5));
        assertNotNull(record);
        assertEquals("emp001", record.key());
    }
}
```

#### Contract Tests (é‡è¦)
**Scope**: ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹é–“ã®APIå¥‘ç´„æ¤œè¨¼  
**Framework**: Pact  
**Coverage Target**: å…¨APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

**Purpose**: 
- Consumerï¼ˆå‘¼ã³å‡ºã—å´ï¼‰ã¨Providerï¼ˆæä¾›å´ï¼‰ã®å¥‘ç´„ä¸ä¸€è‡´ã‚’é˜²ã
- ãƒ‡ãƒ—ãƒ­ã‚¤å‰ã«äº’æ›æ€§ã‚’æ¤œè¨¼

**Example** (Consumerå´):
```java
@Pact(consumer = "LunchApp", provider = "PaymentAPI")
public RequestResponsePact createPaymentPact(PactDslWithProvider builder) {
    return builder
        .given("user emp001 exists")
        .uponReceiving("a request to create payment")
            .path("/api/v1/payments")
            .method("POST")
            .body(new PactDslJsonBody()
                .stringType("employee_id", "emp001")
                .integerType("amount", 850))
        .willRespondWith()
            .status(201)
            .body(new PactDslJsonBody()
                .stringType("payment_id", "pay-12345")
                .stringType("status", "SUCCESS"))
        .toPact();
}
```

**Example** (Providerå´):
```java
@SpringBootTest
@Provider("PaymentAPI")
@PactBroker
class PaymentAPIProviderTest {
    @TestTemplate
    @ExtendWith(PactVerificationInvocationContextProvider.class)
    void pactVerificationTestTemplate(PactVerificationContext context) {
        context.verifyInteraction();
    }
    
    @State("user emp001 exists")
    void userExists() {
        // Setup test data
        employeeRepository.save(new Employee("emp001", "John Doe"));
    }
}
```

#### End-to-End Tests (10%)
**Scope**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªå…¨ä½“ï¼ˆUI â†’ API â†’ DB â†’ Kafkaï¼‰  
**Framework**: 
- Selenium/Playwright (UIè‡ªå‹•åŒ–)
- REST Assured (APIè‡ªå‹•åŒ–)

**Coverage Target**: ä¸»è¦ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¸ãƒ£ãƒ¼ãƒ‹ãƒ¼  
**Execution Time**: < 30 minutes

**Example Scenarios**:
1. ç¤¾å“¡ãŒãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’é–²è¦§ã—ã€æ±ºæ¸ˆã‚’å®Ÿè¡Œã—ã€åˆ©ç”¨æ˜ç´°ã‚’ç¢ºèªã™ã‚‹
2. äººäº‹æ‹…å½“è€…ãŒæœˆæ¬¡è«‹æ±‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹
3. æ±ºæ¸ˆå¤±æ•—æ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### Test Environments

| Environment | Purpose | Data | Refresh Frequency |
|------------|---------|------|------------------|
| Local | é–‹ç™ºä¸­ã®ãƒ¦ãƒ‹ãƒƒãƒˆ/çµ±åˆãƒ†ã‚¹ãƒˆ | Mock/Testcontainers | éƒ½åº¦ |
| Dev | é–‹ç™ºãƒãƒ¼ãƒ çµ±åˆ | Synthetic | Daily |
| Test | QAæ¤œè¨¼ | Anonymized Production Data | Weekly |
| Staging | æœ¬ç•ªå‰æ¤œè¨¼ | Anonymized Production Data | On-demand |
| Production | æœ¬ç•ª | Real Data | N/A |

### Continuous Testing (CI/CD)

```yaml
# CI Pipeline (.gitlab-ci.yml example)
stages:
  - unit-test
  - integration-test
  - contract-test
  - e2e-test
  - deploy

unit-test:
  stage: unit-test
  script:
    - ./gradlew test
  coverage: '/Code coverage: \d+\.\d+%/'
  
integration-test:
  stage: integration-test
  services:
    - postgres:15
    - confluentinc/cp-kafka:7.5.0
  script:
    - ./gradlew integrationTest

contract-test:
  stage: contract-test
  script:
    - ./gradlew pactVerify
  only:
    - merge_requests

e2e-test:
  stage: e2e-test
  environment: test
  script:
    - ./gradlew e2eTest
  only:
    - main
```

### Test Data Management

#### Synthetic Data Generation
**Tool**: Faker, DataFactory  
**Purpose**: ãƒ¦ãƒ‹ãƒƒãƒˆ/çµ±åˆãƒ†ã‚¹ãƒˆç”¨ã®å½ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ

#### Anonymized Production Data
**Tool**: PostgreSQL Anonymizer  
**Purpose**: Test/Stagingç’°å¢ƒã§ã® realistic ãªãƒ‡ãƒ¼ã‚¿  
**Process**:
1. æœ¬ç•ªDBã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—
2. PIIï¼ˆå€‹äººæƒ…å ±ï¼‰ã®ãƒã‚¹ã‚­ãƒ³ã‚°
   - æ°å â†’ ãƒ©ãƒ³ãƒ€ãƒ åå‰
   - ç¤¾å“¡ID â†’ ãƒãƒƒã‚·ãƒ¥åŒ–
   - é‡‘é¡ â†’ ãƒã‚¤ã‚ºä»˜åŠ ï¼ˆÂ±10%ï¼‰
3. Test/Stagingç’°å¢ƒã¸ã®å¾©å…ƒ

### Testability Design Principles

1. **Dependency Injection**: ãƒ¢ãƒƒã‚¯/ã‚¹ã‚¿ãƒ–ã®æ³¨å…¥ãŒå®¹æ˜“
2. **Interface Segregation**: å°ã•ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ä¾å­˜ã‚’åˆ†é›¢
3. **Test Doubles**: ãƒ¢ãƒƒã‚¯ã€ã‚¹ã‚¿ãƒ–ã€ãƒ•ã‚§ã‚¤ã‚¯ã®æ´»ç”¨
4. **Idempotency**: åŒã˜å…¥åŠ›ã§åŒã˜çµæœï¼ˆå†ç¾æ€§ï¼‰
5. **Observability**: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã®ãƒ­ã‚°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‡ºåŠ›

### Test Metrics & Quality Gates

| Metric | Target | Enforcement |
|--------|--------|-------------|
| Unit Test Coverage | > 80% | CI/CD Block |
| Integration Test Coverage | > 60% | CI/CD Warning |
| Contract Test Coverage | 100% (all APIs) | CI/CD Block |
| E2E Test Success Rate | 100% | CI/CD Block |
| Test Execution Time | < 20 min (total) | CI/CD Warning |
```

---

### Proposal 8: Deployment Strategyã®æ˜ç¤º

**å¯¾è±¡**: Target Architecture (`03_arch-artifacts/target/container-diagram.md`)  
**Root Cause**: rc-002 (Upgradeability not considered)  
**Symptom**: rf-005 (Security incident), rf-008 (Unable to accommodate business needs)

#### Target Architectureã¸ã®è¿½åŠ 

```markdown
## Deployment Strategy

### Deployment Patterns

#### Blue-Green Deploymentï¼ˆæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰
**Use Case**: ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã€ç ´å£Šçš„å¤‰æ›´  
**Process**:
1. Greenç’°å¢ƒï¼ˆæ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
2. Smoke testã‚’Greenç’°å¢ƒã§å®Ÿè¡Œ
3. ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’Blueâ†’Greenã«åˆ‡æ›¿ï¼ˆDNS/Load Balancerï¼‰
4. ç›£è¦–å¼·åŒ–ï¼ˆHypercare 24æ™‚é–“ï¼‰
5. å•é¡Œãªã‘ã‚Œã°Blueç’°å¢ƒã‚’å»ƒæ£„

**Rollback**: ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’Greenâ†’Blueã«æˆ»ã™ï¼ˆ< 1åˆ†ï¼‰

---

#### Canary Deploymentï¼ˆæ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆï¼‰
**Use Case**: ãƒã‚¤ãƒŠãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã€æ–°æ©Ÿèƒ½è¿½åŠ   
**Process**:
1. æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’10%ã®Podã«ãƒ‡ãƒ—ãƒ­ã‚¤
2. 10%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
3. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ï¼ˆã‚¨ãƒ©ãƒ¼ç‡ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰
4. å•é¡Œãªã‘ã‚Œã°æ®µéšçš„ã«50% â†’ 100%ã¸
5. æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®Podã‚’å‰Šé™¤

**Canary Analysis Metrics**:
- Error Rate: æ–° vs æ—§ã§æœ‰æ„å·®ãªã—
- Latency (p95): æ–° vs æ—§ã§+10%ä»¥å†…
- Business Metrics: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æˆåŠŸç‡ãŒåŒç­‰

**Rollback**: æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¸ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’0%ã«ï¼ˆ< 5åˆ†ï¼‰

---

#### Rolling Updateï¼ˆé€šå¸¸ã®æ›´æ–°ï¼‰
**Use Case**: ãƒ‘ãƒƒãƒé©ç”¨ã€è¨­å®šå¤‰æ›´  
**Process**:
1. 1 Pod ãšã¤æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æ›´æ–°
2. Readiness Probeã§æº–å‚™å®Œäº†ã‚’ç¢ºèª
3. æ¬¡ã®Podã¸é€²ã‚€
4. å…¨PodãŒæ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ãªã‚‹ã¾ã§ç¹°ã‚Šè¿”ã—

**Configuration** (Kubernetes):
```yaml
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
```

### Version Management

#### Semantic Versioning
**Format**: `MAJOR.MINOR.PATCH`  
**Example**: `1.2.3`

- **MAJOR**: ç ´å£Šçš„å¤‰æ›´ï¼ˆAPIå¥‘ç´„ã®å¤‰æ›´ï¼‰
- **MINOR**: å¾Œæ–¹äº’æ›æ€§ã®ã‚ã‚‹æ©Ÿèƒ½è¿½åŠ 
- **PATCH**: ãƒã‚°ä¿®æ­£ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒ

#### Container Image Tagging
```
registry.example.com/canteen/payment-api:1.2.3
                      ^service  ^app     ^version
```

**Tag Strategy**:
- `1.2.3`: Immutable, specific version
- `1.2`: Latest patch in 1.2.x
- `1`: Latest minor in 1.x.x
- `latest`: Latest version (non-production only)

### Database Migration Strategy

#### Expand-Contract Patternï¼ˆå¾Œæ–¹äº’æ›æ€§ã‚’ä¿ã¤ï¼‰

**Phase 1: Expandï¼ˆæ‹¡å¼µï¼‰**
- æ–°ã—ã„ã‚«ãƒ©ãƒ /ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¿½åŠ 
- æ—§ã‚«ãƒ©ãƒ ã¯ç¶­æŒ
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ–°æ—§ä¸¡æ–¹ã«æ›¸è¾¼ã¿

**Phase 2: Migrateï¼ˆç§»è¡Œï¼‰**
- ãƒ‡ãƒ¼ã‚¿ã‚’æ—§ã‚«ãƒ©ãƒ ã‹ã‚‰æ–°ã‚«ãƒ©ãƒ ã¸ç§»è¡Œ
- ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ

**Phase 3: Contractï¼ˆç¸®å°ï¼‰**
- æ—§ã‚«ãƒ©ãƒ ã¸ã®å‚ç…§ã‚’å‰Šé™¤
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤
- æ—§ã‚«ãƒ©ãƒ ã‚’å‰Šé™¤

#### Migration Tools
- **Flyway** or **Liquibase**: Schema migrationç®¡ç†
- **Versioned SQL scripts**: `V1__initial_schema.sql`, `V2__add_payment_status.sql`

### Configuration Management

#### External Configuration
**Tool**: Kubernetes ConfigMap + Secret  
**Strategy**: 
- ç’°å¢ƒå›ºæœ‰ã®è¨­å®šã¯ConfigMapã§ç®¡ç†
- æ©Ÿå¯†æƒ…å ±ï¼ˆDB passwordã€API keyï¼‰ã¯Secretã§ç®¡ç†
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãƒã‚¦ãƒ³ãƒˆã•ã‚ŒãŸè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­è¾¼ã¿

**Example**:
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: payment-api-config
data:
  application.yaml: |
    spring:
      datasource:
        url: jdbc:postgresql://payment-db:5432/paymentdb
    kafka:
      bootstrap-servers: kafka:9092
```

### Rollback Strategy

#### Automated Rollback Triggers
- Error Rate > 5% for 2 minutes
- Latency (p95) > SLO Ã— 2 for 5 minutes
- Availability < 95% for 5 minutes

#### Manual Rollback Process
1. On-call engineeråˆ¤æ–­
2. Rollbackå®Ÿè¡Œï¼ˆBlue-Green: ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ‡æ›¿ã€Canary: ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯0%ï¼‰
3. ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
4. Root Cause Analysisï¼ˆ48æ™‚é–“ä»¥å†…ï¼‰

### Maintenance Window

#### Scheduled Maintenance
- **Frequency**: Monthly (ç¬¬2æ°´æ›œæ—¥ 2:00-5:00 AM)
- **Duration**: æœ€å¤§3æ™‚é–“
- **Scope**: 
  - Database schema migration
  - Major version upgrade
  - Infrastructure maintenance

#### Emergency Maintenance
- **Trigger**: Critical security vulnerability, Major incident
- **Notification**: 1 hour advance (if possible)
- **Process**: ç°¡ç•¥åŒ–ã•ã‚ŒãŸæ‰¿èªãƒ—ãƒ­ã‚»ã‚¹
```

---

## Summary of Proposals

| # | Title | Priority | Root Cause | Target File | Status |
|---|-------|----------|-----------|-------------|--------|
| 1 | DRæˆ¦ç•¥ã®ç­–å®š | ğŸ”´ Critical | rc-019, rc-030, rc-018 | Target Architecture | Draft |
| 2 | å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æºã®æ˜ç¤º | ğŸ”´ Critical | rc-012 | Target Architecture | Draft |
| 3 | ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼æ–¹æ³•ã®ç¢ºå®š | ğŸ”´ Critical | rc-027 | Step 1, 2 | Draft |
| 4 | ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£è¨ˆç”»ã®ç­–å®š | ğŸŸ¡ High | rc-017, rc-011 | Baseline, Target | Draft |
| 5 | é‹ç”¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ˜ç¤º | ğŸŸ¡ High | rc-024 | Target Architecture | Draft |
| 6 | Data Contractã®æ˜ç¤º | ğŸŸ¢ Medium | rc-028 | Step 1, 2 | Draft |
| 7 | ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã®æ˜ç¤º | ğŸŸ¢ Medium | rc-020 | Target Architecture | Draft |
| 8 | Deployment Strategyã®æ˜ç¤º | ğŸŸ¢ Medium | rc-002 | Target Architecture | Draft |

---

## Next Steps

1. **Review**: ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ï¼ˆEAã€SREã€é–‹ç™ºãƒãƒ¼ãƒ ã€ãƒ“ã‚¸ãƒã‚¹ï¼‰ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼
2. **Prioritize**: Criticalé …ç›®ã‚’æœ€å„ªå…ˆã§å¯¾å¿œ
3. **Update Artifacts**: æ‰¿èªã•ã‚ŒãŸææ¡ˆã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã«åæ˜ 
4. **Validate**: Backcasting Mapã§å†åº¦ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯
5. **Document**: ADRã§æ„æ€æ±ºå®šã‚’è¨˜éŒ²

---

**Document Status**: Draft  
**Last Updated**: 2025-11-13  
**Reviewer**: (To be assigned)

